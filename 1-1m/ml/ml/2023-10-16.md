PAC learning in modelli più generali
REALIZABILITY: esiste $h^* \in \mathbb{H} | L_{\mathbb{D},f}(h^*) = 0$ -> label determinata totalmente da istanza
Ipotesi rimossa: AGNOSTIC PAC LEARNING
Ipotesi realizability è molto vincolante in molte applicazioni
Rilassamento: $\mathbb{D}$ è distribuzione su $\mathbb{X} \times \mathbb{Y}$ (dist. congiunta) -> prima $\forall \vec{x} \in \mathbb{X} \exists y | \mathbb{Pr} [y|\vec{x}]=1$
$\mathbb{D}_x$: distr. marginale; $\mathbb{D}((x,y)|x)$
Label ottenuta da prob. condizionata $\mathbb{Pr} [y|x]$

Con questa distribuzione, non esiste più $f(x)$ -> true error:
$$L_{\mathbb{D}} (h) = \mathbb{Pr}_{(x,y) \sim \mathbb{D}} [h(x) \neq y]$$
Empirical risk uguale: non so distr. quindi non mi interessa -> qui, probabilità che per coppia (istanza, label) presa uniformemente a random da training set avvenga evento "label diverse" -> quindi, generalization=empirical

Obbiettivo: minimizzare generalization -> esiste miglior predittore? -> data distr. su $\mathbb{X} \times \{ 0,1 \}$, miglior predittore è BAYES OPTIMAL PREDICTOR:
$f_{\mathbb{D}} = 1$ se $\mathbb{P}[y=1|x] \geq 1/2, 0$ altrimenti -> vale $L_{\mathbb{D}} (f_{\mathbb{D}}) \leq L_{\mathbb{D}}(g)$ per ogni classificatore $g$
Non si può usare perchè non sappiamo probabilità, dato che non sappiamo distr.

AGNOSTIC PAC LEARNABILITY
Consideriamo classe di ipotesi $\mathbb{H}$ -> ci basterà trovare predittore quasi buono
Problema è AGNOSTIC PAC LEARNABLE se errore è vicino di $\epsilon$ di miglior errore possibile -> già più realistico -> miglior errore possibile si stima da training

Oltre classificazione binaria
Definizioni di agnostic PAC learnable per MULTICLASS CLASSIFICATION sono identiche
Diverso per REGRESSIONE

REGRESSIONE
- Dominio: $\mathbb{R}^p$ per qualche p
- Target: $\mathbb{R}$
- Traning data, output uguale
- Loss function deve essere cambiata -> infiniti valori, errori possono essere così piccoli da poter essere trascurati
Serve GENERALIZED LOSS FUNCTION: $$l : \mathbb{H} \times Z \rightarrow \mathbb{R}_+$$(classe di ipotesi x dominio)
TRUE RISK FUNCTION: aspettazione di loss per ipotesi $h$ $$L_{\mathbb{D}} (h) = \mathbb{E}_{z \sim \mathbb{D}} [l(h,z)]$$
EMPIRICAL RISK: con training set $S = (z_1,...,z_m) \in Z^m$ $$L_S (h) = \frac{1}{m} \sum_{i=1}^m l(h,z_i)$$
Loss function comuni:
- 0-1 LOSS: 0 se label uguali, 1 altrimenti $$l_{0-1} = \begin{cases} 0, \mbox{ if } h(x)=y \\ 1, \mbox{ if } h(x) \neq y \end{cases}$$
- SQUARED LOSS: per regressione -> con questo trovare buona ipotesi è facile -> molto meglio di absolute value loss per ragioni di computazione $$l_{sq} (h,(x,y)) = (h(x)-y)^2$$
Come scegliere loss function?
	esempio: classificazione di impronte digitali: prendere immagine di impronta digitali e usare funzione di ML f e produce label 1 se accesso valido, 0 altrimenti
	abbiamo due tipi di errori: accessi falsi e rifiuti falsi
	consideriamo tabella con valori veri, predetti, valori associati di loss: $$\begin{bmatrix} & | & +1 & -1 \\ - & - & - & - \\ +1 & | & \mbox{no errore}=0 & \mbox{accesso falso}=1 \\ -1 & | & \mbox{rifiuto falso}=1 & \mbox{no errore}=0 \end{bmatrix}$$
	non sempre top -> se fosse accesso a codici nucleari? -> meglio: $$\begin{bmatrix} & | & +1 & -1 \\ - & - & - & - \\ +1 & | & 0 & 100 \\ -1 & | & 1 & 0 \end{bmatrix}$$
	se fossi in supermercato per dare sconti? $$\begin{bmatrix} & | & +1 & -1 \\ - & - & - & - \\ +1 & | & 0 & 1 \\ -1 & | & 10 & 0 \end{bmatrix}$$
	a seconda della situazione, pensare a loss migliore

Agnostic PAC learnability per general loss functions: definizione diventa (per certa loss function): $$L_{\mathbb{D}} (h) = \mathbb{E}_{z \sim \mathbb{D}} [l(h,z)]$$
## MODELLI LINEARI
$\mathbb{X}=\mathbb{R}^d$
LINEAR AFFINE FUNCTIONS: $$L_d = \{ h_{\textbf{w},b} | \textbf{w} \in \mathbb{R}^d, b \in \mathbb{R} \}$$$$h_{\textbf{w},b} = \langle \textbf{w}, \textbf{x} \rangle + b = (\sum_{i=1}^d w_ix_i) + b$$
- x,b: parametri; x: vettore di caratteristiche; b: BIAS
- ogni membro di $L_d$ è funzione

Classe di ipotesi: $$\mathbb{H} : \phi \circ L_d \mbox{, con } \phi : \mathbb{R} \rightarrow \mathbb{Y}$$
$\phi$ dipende da problema di apprendimento -> binary classification: sign function; regressione: funzione identità

Notazione equivalente: data istanza, vettore di caratteristiche e bias
- $\textbf{w}' = (b,w_1,...,w_d) \in \mathbb{R}^{d+1}$
- $\textbf{x}' = (1,x_1,...,x_d) \in \mathbb{R}^{d+1}$
Così: $$h_{\textbf{w},b}(\textbf{x}) = \langle \textbf{w}, \textbf{x} \rangle + b = \langle \textbf{w'}, \textbf{x'} \rangle$$
Consideremo bias come parte di $\textbf{w}$ e assumere che 1 sia in $\textbf{x}$ se necessario

Linear classification:
	$\mathbb{X} = \mathbb{R}^2$ -> istanze: punti nello spazio -> classificatore lineare come linea che assegna label a lati
	$\textbf{w}$ sarà come vettore normale a classificatore
	informazioni label rappresentate con simbolo punti