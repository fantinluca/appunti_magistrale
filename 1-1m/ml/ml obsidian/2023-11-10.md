Cont. dim:
	ora vogliamo limitare termini di $(**)$ con Hoeffding: $$L_\mathbb{D}(h)=\mathbb{E}_{z\sim\mathbb{D}}[l(h,z)], \quad L_S(h)=\frac{1}{m}\sum_{i=1}^m l(h,z_i)$$Importante: dato che ogni $z_i$ sampled i.i.d. da $\mathbb{D}$: $$\mathbb{E}[l(h,z_i)]=\mathbb{E}_{z\sim\mathbb{D}}[l(h,z)]=L_\mathbb{D}(h)$$Perciò: $$\mathbb{E}[L_S(h)] = \mathbb{E}\left[\frac{1}{m}\sum_{i=1}^ml(h,z_i)\right]=\frac{1}{m}\mathbb{E}[l(h,z_i)]=\frac{1}{m}mL_\mathbb{D}(h)=L_\mathbb{D}(h)$$Definiamo $\theta_i$ rv data da $l(h,z_i)$ -> dato che $h$ è fissato e $z_i$ è preso iid da distribuzione $\mathbb{D}$ -> $\theta_1,...,\theta_m$ sono rv iid
	Notiamo che $$L_s(h)=\frac{1}{m}\sum_{i=1}^m\theta_i$$Definiamo $\mu=L_\mathbb{D}(h)$
	Data assunzione che $l:\mathbb{H}\times Z\rightarrow[0,1]$, abbiamo $\theta\in[0,1]\ \forall i\in[1,m]$, usiamo Hoeffding con $a_i=0,b_i=1\ \forall i\in[1,m]$: $$\mathbb{D}(\{S:|L_S(h)-L_\mathbb{D}(h)|>\varepsilon\}) = \mathbb{Pr}\left[\left|\left(\frac{1}{m}\sum_{i=1}^m\theta_i\right)-\mu\right|>\varepsilon\right] \leq 2e^{-2m\varepsilon^2}$$Combinando questa disuguaglianza con $(**)$: $$\mathbb{D}(\{S:\exists h\in\mathbb{H} |L_S(h)-L_\mathbb{D}(h)|>\varepsilon\}) \leq \sum_{h\in\mathbb{H}}2e^{-2m\varepsilon^2}=2|\mathbb{H}|e^{-2m\varepsilon^2}$$
	Scegliamo: $$m\geq \text{log}(\frac{2|\mathbb{H}|}{\delta})\frac{1}{2\varepsilon^2} \quad \mathbb{D}(\{S:\exists h\in\mathbb{H} |L_S(h)-L_\mathbb{D}(h)|>\varepsilon\}) \leq 2|\mathbb{H}|e^{-2\varepsilon^2log(\frac{2|\mathbb{H}|}{\delta})\frac{1}{2\varepsilon^2}}=\delta$$Per esempio $m=\lceil log(\frac{2|\mathbb{H}|}{\delta})\frac{1}{2\varepsilon^2}\rceil$

## BIAS-COMPLEXITY TRADE-OFF
Learning: dato training set, loss function vogliamo ipotesi con basso generalization error -> possiamo decidere algoritmo di apprendimento (dato training set produce ipotesi) -> algoritmo contiene classe di ipotesi e processo per scegliere ipotesi -> esiste algoritmo che prevede miglior ipotesi per qualunque distribuzione?
NO FREE LUNCH THEOREM (dipende da compito):
	sia $A$ learning algoritmo per binary classification con 0-1 loss su dominio $X$, sia  $m<|X|/2$ training set size, allora esiste distribuzione $\mathbb{D}$ su $X\times\{0,1\}$ tale che esiste funzione $f:X\rightarrow\{0,1\}$ con generalization error nullo e con probabilità almento 1/7 su scelta di $S\sim\mathbb{D}^m$ abbiamo $L_\mathbb{D}(A(S))\geq1/8$
Altra fomulazione:
	sia $X$ dominio infinito, $\mathbb{H}$ insieme di tutte funzioni $X\rightarrow\{0,1\}$, allora $\mathbb{H}$ non è PAC learnable
Quindi devo restringere classe di ipotesi -> per farlo bene devo usare conoscenza pre-esistente su $\mathbb{D}$ -> come scegliere classe:
- grande così potrebbe contenere ipotesi con piccolo generalization error
- non troppo grande (no free lunch)
Usiamo ERROR DECOMPOSITION: dato $h_S$ ipotesi scelta da $\text{ERM}_\mathbb{H}$, $$L_\mathbb{D}(h_S)=L_\mathbb{D}(h_S)-\text{min}_{h\in\mathbb{H}}L_\mathbb{D}(h)+\text{min}_{h\in\mathbb{H}}L_\mathbb{D}(h)$$
- $\varepsilon_{app} := \text{min}_{h\in\mathbb{H}}L_\mathbb{D}(h)\geq0$: APPROXIMATION ERROR
	quanto bene ho scelto classe di ipotesi -> dopo averla scelta è inevitabile -> per diminuirlo scegliere classe più grande
- $\varepsilon_{est}:=L_\mathbb{D}(h_S)-\text{min}_{h\in\mathbb{H}}L_\mathbb{D}(h)$: ESTIMATION ERROR
	quanto male ho trovato ipotesi -> può essere evitato scegliendo miglior ipotesi -> per diminuirlo, serve piccolo numero di ipotesi, così training error è buona stima di generalization error per tutte -> serve classe più piccola
Plot di $L_\mathbb{D}(h_S)$: parabola verso l'alto
- grande approximation error (bassa complessità, grande inductive bias): UNDERFITTING
- grande estimation error (altà complessità, basso inductive bias): OVERFITTING

Come stimare generalization error per ipotesi? -> usare TEST SET: tenere da parte sample per testare (non usati per scegliere ipotesi)

## MODEL SELECTION AND VALIDATION
In machine learning task, scegliamo tra algoritmi con parametri -> come scegliere valori di parametri (non usati per predizioni, ma specificano classe di ipotesi)?
Es:
	regression task, scegliamo polinomi -> proviamo a prendere training error di migliori ipotesi per vari gradi di polinomi -> training error non basta -> dopo aver scelto miglior classe, troviamo migliore ipotesi con nuovi dati