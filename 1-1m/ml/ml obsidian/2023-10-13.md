Come usare bene ERM: usare RESTRICTED SET di ipotesi $\mathbb{H}$: classe di ipotesi
Ogni $h \in \mathbb{H}$ è funzione $h:\mathbb{X} \rightarrow \mathbb{Y}$
Modello scelto da ERM considerando solo modelli di $\mathbb{H}$: $$\text{ERM}_{\mathbb{H}} \in \text{argmin}_{h \in \mathbb{H}} L_S(h)$$
(potrei avere più modelli che minimizzano errore)

Quali classi di modelli non provocano overfitting?
Iniziamo molto restrittivi -> classi finite: $\mathbb{H} < \infty$
	Es: problema film
	$\vec{x} = [x_1, x_2] \in \mathbb{R}^2, \mathbb{Y} = \{ -1,1 \}$
	$\mathbb{H} = \{ h_{a,b}(\vec{x}) | h_{a,b}(\vec{x}) = \text{sign}(ax_1+bx_2), a,b \in \mathbb{R} \}$ (es. $x_1$ quanto del film è azione, $x_2$ quanto è romance; segno + piace il film, segno - non piace il film)
	$\mathbb{H}$ infinito -> per scegliere modello fisso $a,b$

Supponiamo $\mathbb{H}$ finito, sia $h_S$ output di $\text{ERM}_{\mathbb{H}}(S)$
Supponiamo:
- REALIZABILITY: esiste $h^* \in \mathbb{H}$ con generalization error nullo
- I.I.D: esempi in training set sono i.i.d. rispetto a $\mathbb{D}$: $S \sim \mathbb{D}^m$
Se realizability vale, $L_S(h^*)=0$ -> ma possiamo imparare miglior modello? -> non esiste garanzia

PROBABLY APPROXIMATELY CORRECT (PAC) learning framework
Dato che training data viene da $\mathbb{D}$, possiamo solo essere approssimativamente corretti -> possiamo solo essere probabilmente corretti
Parametri per formalizzare:
- ACCURACY PARAMETER $\epsilon$: siamo soddisfatti da buona ipotesi: $h_S | L_{\mathbb{D}, f} (h_S) \leq \epsilon$
- CONFIDENCE PARAMETER $\delta$: vogliamo che venga fuori buona ipotesi con probabilità $\geq 1-\delta$
Vogliamo valori piccoli

TEOREMA: $\mathbb{H}$ classe finita, $\forall f, \mathbb{D}$ per cui realizability vale, $\delta, \epsilon \in (0,1)$; supponiamo $|S| = m \in \mathbb{N} | m \geq \frac{log(|\mathbb{H}|/\delta)}{\epsilon}$ (log: logaritmo naturale); con probabilità $\geq 1 - \epsilon$ troviamo che per ogni ipotesi ERM $h_S$ vale $L_{\mathbb{D},f}(h_S) \leq \epsilon$
Altra formulazione: con classi di ipotesi finite $\mathbb{H}$ posso quasi sempre (prob. $\geq 1-\delta$) trovare buona ipotesi ($L_{\mathbb{D},f}(h_S) \leq \epsilon$) se ho abbastanza dati ($m \geq \frac{log(|\mathbb{H}|/\delta)}{\epsilon}$)
Parte del teorema ottimo per machine learning: $\forall f, \mathbb{D}$ -> posso applicare ERM in qualunque situazione
Dimostrazione:
	- sia $S|_x = \{ x_1,...,x_m \}$ esempi in training set S -> vogliamo limitare superiormente $\mathbb{D}^m(\{ S|_x | L_{\mathbb{D},f}(h_S) > \epsilon \})$
	- chiamiamo $\mathbb{H}_B = \{ h \in \mathbb{H} | L_{\mathbb{D},f}(h) > \epsilon \}$ (insieme di brutte ipotesi), $M = \{ S|_x | \exists h \in \mathbb{H}_B, L_S(h) = 0 \}$ (MISLEADING SAMPLES, possono portare a brutta ipotesi)
	- per realizability, $L_s(h_S)=0$, quindi $L_{\mathbb{D},f} (h_S) > \epsilon \iff \exists h \in \mathbb{H}_B | L_S(h)=0$ -> training data deve essere in M: $\{ S|_x | L_{\mathbb{D},f} (h_S) > \epsilon \} \subseteq M$
	- notiamo che $M = \cup_{h \in \mathbb{H}_B} \{ S|_x | L_S(h)=0 \}$ -> possiamo scrivere $\mathbb{D}^m (\{ S|_x | L_{\mathbb{D},f} (h_S) > \epsilon \}) \leq \mathbb{D}^m(M)$ (a causa di sottoinsiemi) -> $= \mathbb{D}^m (\cup_{h \in \mathbb{H}_B} \{ S|_x | L_S(h)=0 \})$
	- $P(A\cup B) \leq P(A)+P(B)$: UNION BOUND -> $\leq \sum_{h \in \mathbb{H}_B} \mathbb{D}^m (\{ S|_x | L_S(h)=0 \})$ (i)
	- fissiamo $h \in \mathbb{H}_B | L_S(h)=0$ <-> $\forall i \in [1,m] h(x_i)=f(x_i)$ -> $\mathbb{D}^m(\{ S|_x | L_S(h)=0 \}) = \mathbb{D}^m (\{ S|_x | \forall i \in [1,m] h(x_i)=f(x_i) \}) = \Pi_{i=1}^m \mathbb{D}(\{ x_i | h(x_i)=f(x_i) \})$ ($x_i$ sono i.i.d.)
	- poniamo $i \in [1,m]$: $\mathbb{D} (x_i | h(x_i)=f(x_i)) = 1 - \mathbb{D}(\{ x_i | h(x_i) \neq f(x_i) \}) = 1 - L_{\mathbb{D},f}(h)$
	- dato che è cattiva ipotesi, $1 - L_{\mathbb{D},f}(h) \leq 1 - \epsilon$
	- espansione di Taylor: $1- \epsilon \leq e^{- \epsilon}$ (ii)
	- combiniamo con (ii): $\mathbb{D}^m(\{ S|_x | L_S(h)=0 \}) \leq \Pi_{i=1}^m e^{- \epsilon} = e^{-m\epsilon}$
	- combiniamo con (i): $\mathbb{D}^m(\{ S|_x | L_S(h)=0 \}) \leq \sum_{h \in \mathbb{H}_B} e^{-m\epsilon} = |\mathbb{H}_B| \cdot e^{-\epsilon} \leq |\mathbb{H}| \cdot e^{-m\epsilon}$
	- data la scelta di m in ipotesi, abbiamo $\leq |\mathbb{H}| \cdot e^{-\epsilon \cdot \frac{1}{2} log(|\mathbb{H}|/\delta)} = |\mathbb{H}| \cdot \frac{\delta}{|\mathbb{H}|} = \delta$
Per classi infinite, dimostrazione molto più difficile

PAC LEARNABILITY
Classe di ipotesi $\mathbb{H}$ è PAC LEARNABLE se esiste funzione che dice quanti dati avere e algoritmo di apprendimento tale che per ogni valore dei parametri, per ogni distribuzione in input e per ogni funzioni di label, se realizability vale rispetto a queste cose; allora quando eseguo algoritmo su almeno i.i.d esempi, algoritmo restituisce ipotesi tale che ipotesi buona con buona probabilità

Classi finite sono PAC learnable con algoritmo ERM con sample complexity inferiore a certo valore
Funzione che dice quanti dati avere: SAMPLE COMPLEXITY

Vogliamo togliere ipotesi e continuare a usare metodo