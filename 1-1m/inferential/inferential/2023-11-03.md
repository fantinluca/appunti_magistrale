$L$ utile soprattutto con dominio e codominio infiniti -> più utile usare $\text{log}L(\theta)=l(\theta)$ (log naturale) quando $L>0 \ \forall \theta\in\Theta$
Possibile plottare SCALED LIKELIHOOD FUNCTION
Con più sample, intervallo di valori possibili si restringe -> $L$ diventa più "informativa" -> si può esprimere con OBSERVED INFORMATION: $$J(\theta)=-\frac{d^2l(\theta)}{d\theta^2}$$Abbiamo che $J\geq0$ e più alto $J$ più peaked è likelihood
Spesso si usa $J_n(\theta)$ per sottolineare valore di $n$
Per calcolare maximum likelihood estimate:
- calcolare gradiente di log-likelihood
- trovare $\theta^*|l'(\theta^*)=0$ (LIKELIHOOD EQUATION)
- se $J(\theta^*)>0$, $\hat{\theta}=\theta^*$
Così sappiamo solo se $\hat{\theta}$ è massimo locale
	es: $$L(\theta)=\theta^7(1-\theta)^3 \quad \Rightarrow \quad l(\theta)=7log\theta + 3log(1-\theta) \quad \Rightarrow \quad l'(\theta)=\frac{7}{\theta}-\frac{3}{1-\theta}=0 \quad \Rightarrow \quad \hat{\theta}=0.7$$
Se non possiamo risolvere likelihood equation analiticamente, usare metodi numerici -> più usato: NEWTON-RAPHSON METHOD:
	costruire sequenza $\tilde{\theta}_1, \tilde{\theta}_2,...$ che converge a $\hat{\theta}$: $$\tilde{\theta}_{m+1}=\tilde{\theta}_{m}+\frac{l'(\tilde{\theta}_m)}{J(\tilde{\theta}_m)}$$$\tilde{\theta}_0$: valore iniziale -> serve stabilire condizione per fermarsi

Si può applicare $L$ con parametro a vettore
	es:
	$X_i \sim Wei(\alpha,1/\beta) \rightarrow \theta=(\alpha,\beta)$, iid sample
	likelihood diventa $L(\alpha,\beta):\mathbb{R}_{>0}\times\mathbb{R}_{>0}\rightarrow\mathbb{R}_{>0}$ -> rappresentata con curve di livello -> può essere più semplice visualizzare log-likelihood
	funzioni in R per visualizzare surface: persp, image

Es:
	$X_1,...,X_n \sim \text{Unif}(0,\theta), \theta>0$ -> modello: $$\left\{\prod_{i=1}^n\frac{1}{n}\textbf{1}_{[0,\theta]}(x_i):\theta\in\mathbb{R}_{>0}\right\}$$likelihood function: $$L(\theta)=\begin{cases} 1/\theta^n & \mbox{if }x_{(n)}\leq\theta \\ 0 & \mbox{otherwise}\end{cases}$$(se c'è una variabile maggiore di $\theta$, $\textbf{1}_{[0,\theta]}$ ritorna 0)
	può essere nulla -> non possiamo calcolare log-likelihood

Per parametri vettoriali, observed information: $$J(\theta)=-1\begin{pmatrix}\frac{\partial^2l(\theta)}{\partial\theta_1^2} & ... & \frac{\partial^2l(\theta)}{\partial\theta_1\partial\theta_p} \\ . & . & . \\ . & . & . \\ . & .& . \\ \frac{\partial^2l(\theta)}{\partial\theta_p\theta_1} & ... & \frac{\partial^2l(\theta)}{\partial\theta_p^2}\end{pmatrix}$$Matrice simmetrica -> esprimibile come $$J(\theta)=[J(\theta)_{ij}]=\left[-\frac{\partial^2l(\theta)}{\partial\theta_i\partial\theta_j}\right]$$Notazione:
- $J(\theta)_{ij}$ cella $i,j$
- $J(\theta)^{ij}$ cella $i,j$ di $J^{-1}$
- $\hat{J}=J(\hat{\theta})$