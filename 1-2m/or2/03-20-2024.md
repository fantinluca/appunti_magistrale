Alternativa a tabu search: VARIABLE NEIGHBOURHOOD SEARCH (VNS)
Tabu search:
	prima fase di miglioramento: INTENSIFICAZIONE -> poi, risaliamo: DIVERSIFICAZIONE -> diversificazione saranno molto lunghe -> tempo "sprecato"
VNS:
	diversificazione semplice -> quando arriva a minimo, genera soluzione random e riparte da quella
	tecnica simile a MULTISTART -> difetto: intensificazione molto lunga -> sarebbe meglio non generare soluzione totalmente random
	VNS: creiamo gerarchia di intorni a raggio variabile (2-opt, 3-opt, etc.) -> quando sono fermo in ottimo locale con 2-opt, mi sposto in intorno 3-opt -> da soluzione ottima, genero tre lati random e mi sposto; da lì riparto con 2-opt -> sicuramente non potrò tornare in intorno precedente (dovrei spostare 3 lati anziché 2)
HW: algoritmo VNS con:
	- funzione 2-opt normale
	- funzione kick per deformare soluzione -> metodo più semplice: scambio random di 3 lati -> generiamo 3 numeri $i<j<k$, e riconnettiamo vertici a quegli indici -> suggerimento: creare copia per modificare soluzione; riconnettere in modo fisso
Potrei implementare equivalente con 4/5 lati -> ma chiamare funzione kick due volte di fila basta -> posso farlo qualche volta -> possibilità: scegliere a random quante volte tra 2 e 9

Come confrontare algoritmi, soprattutto di ottimizzazione? -> può anche essere stesso algoritmo con diversi parametri
Non esiste unico metodo migliore
Confrontare metodi: lanciare codice tante volte con stessa istanza ma diversi parametri
Istanze di test (TEST-BED): scegliere tra quelle d'interesse per problema:
- qui, immaginiamo di poterle generare random (random uniform 2-D) (prendere istanze da TSPLIB: meglio di no)
- quanti nodi? -> poniamo n=5000 -> coordinate 0-10000
- timelimit? -> poniamo 120 secondi
- quante istanze? -> dovrebbero essere migliaia -> qui poniamo 10
- cambiare seed tra sessioni di test
Come dire che un algoritmo è migliore dell'altro -> timelimit fisso: vince soluzione migliore
Conviene automatizzare raccolta dati
Come capire bontà algoritmo:
- calcolare media di risultati istanza su varie istanze, poi prenda media minima -> statisticamente poco affidabile: media può dipendere molto da situazione in unica istanza
- media geometrica -> statisticamente più affidabile, meno sensibile ad outlier -> dati n valori, faccio $(\prod_i x_i)^{1/n}$ -> equivalente a media di logaritmi
- classifica stile Formula 1 -> F1-SCORE
In tesina, in sezione dove confrontiamo algoritmi, usare PERFORMANCE PROFILE:
	file csv: righe istanze, colonne algoritmi (prima colonna con nome istanza) -> plottiamo dati con Python fornita
	plot risultante:
	- in asse x, rapporti tra costi -> prendere prima istanza, faccio andare algoritmi -> trovo algoritmo vincitore -> prendo tutti costi e li divido per costo vincitore
	- in asse y, quante volte tale algoritmo ha valori <5 -> e.g. in 90% è stato entro fattore 5 di migliore